{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scats Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_107424\\782242649.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Signalfilt5_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "site_id = 2368\n",
    "date_value = 20230308\n",
    "Datapath: Path('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS')\n",
    "\n",
    "# Create the 'Output' folder inside the Datapath\n",
    "output_folder = Path('Output')\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Read the 2 CSV files for Signal Phasing and Traffic Count data.CSV file as dataframe \n",
    "Signal5df = pd.read_csv('WEST_20230308.SM.csv')\n",
    "#Signal5df\n",
    "# Get the unique Site_ID values\n",
    "site_id_list = Signal5df['Site_ID'].unique().tolist()\n",
    "site_id_list\n",
    "# Get the unique date values\n",
    "date_value_list = Signal5df['Date'].unique().tolist()\n",
    "\n",
    "# Get the unique date values\n",
    "date_value_list = Signal5df['Date'].unique().tolist()\n",
    "\n",
    "# Create a folder for each unique date inside the 'Output' folder\n",
    "for date_value in date_value_list:\n",
    "    date_folder = Path('Output/str(date_value)')  # Construct the path for the date folder\n",
    "    date_folder.mkdir(exist_ok=True)  # Create the date folder if it doesn't exist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TraffCountCHK5df = pd.read_csv('WEST_20230308.VS.csv')\n",
    "#TraffCountCHK5df\n",
    "\n",
    "# Cleaning and manipulating the data on Signal Phasing: \n",
    "\n",
    "# Convert 'Cycle_starttime' and 'Date' columns to datetime format\n",
    "Signal5df['Cycle_ starttime'] = pd.to_datetime(Signal5df['Cycle_ starttime'])\n",
    "Signal5df['Date'] = pd.to_datetime(Signal5df['Date'])\n",
    "# Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "Signal5df['Rounded_Time'] = Signal5df['Cycle_ starttime'].dt.floor('5T')\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "Signal5df['Combined_DateTime'] = Signal5df['Date'].astype(str) + ' ' + Signal5df['Rounded_Time'].dt.time.astype(str)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "Signal5df = Signal5df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "# Move the 'Combined_DateTime' column to be the 5th column\n",
    "cols = list(Signal5df.columns)\n",
    "cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "Signal5df = Signal5df[cols]\n",
    "#Filter the rows in the 'Signal5df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "Signalfilt5_df = Signal5df[Signal5df['Site_ID'] == site_id]\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "Signalfilt5_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "Signalfilt5_df = Signalfilt5_df.drop('Cycle_ starttime', axis=1)\n",
    "# Print the updated DataFrame\n",
    "#Signalfilt5_df\n",
    "# Specify the path and filename for the CSV file\n",
    "Signalfilt5 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Signalfilt5.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "Signalfilt5_df.to_csv(Signalfilt5, index=False)\n",
    "Signalfilt5_df\n",
    "\n",
    "# Cleaning and manipulating the data on Traffic Count: \n",
    "\n",
    "# Convert 'Start_time' column in Traffic Count data to datetime format\n",
    "TraffCountCHK5df['Start_time'] = pd.to_datetime(TraffCountCHK5df['Start_time'])\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHK5df['Combined_DateTime'] = TraffCountCHK5df['Date'].astype(str) + ' ' + TraffCountCHK5df['Start_time'].dt.time.astype(str)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHK5df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK5df['Combined_DateTime'])\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHK5df['Rounded_Combined_DateTime'] = TraffCountCHK5df['Combined_DateTime'].dt.floor('5min')\n",
    "#Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "filtered5_df = TraffCountCHK5df[TraffCountCHK5df['Site_ID'] == site_id]\n",
    "# Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "pivoted5_df = filtered5_df.pivot(index=['Combined_DateTime', 'Site_ID'], columns='Detector_ID', values='Traffic_Volume')\n",
    "# Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "pivoted5_df = pivoted5_df.reset_index()\n",
    "# Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "TrCountmerged5_df = filtered5_df.merge(pivoted5_df, on=['Combined_DateTime', 'Site_ID'], how='left')\n",
    "# Remove the 'Combined_DateTime' column\n",
    "TrCountmerged5_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "TrCountmerged5_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "# Drop the 'Detector_ID' column\n",
    "TrCountmerged5_df.drop('Detector_ID', axis=1, inplace=True)\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "TrCountmerged5_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "TrCountmerged5_df = TrCountmerged5_df.drop(['Start_time', 'Traffic_Volume'], axis=1)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TrCountmerged5_df['Combined_DateTime'] = pd.to_datetime(TrCountmerged5_df['Combined_DateTime'])\n",
    "# Print the updated DataFrame\n",
    "TrCountmerged5_df\n",
    "# Specify the path and filename for the CSV file\n",
    "TrCountmerged5 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/TrCountmerged5.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "TrCountmerged5_df.to_csv(TrCountmerged5, index=False)\n",
    "TrCountmerged5_df\n",
    "\n",
    "# Convert datetime column to string in both dataframes\n",
    "Signalfilt5_df['Combined_DateTime'] = Signalfilt5_df['Combined_DateTime'].astype(str)\n",
    "TrCountmerged5_df['Combined_DateTime'] = TrCountmerged5_df['Combined_DateTime'].astype(str)\n",
    "\n",
    "# Merge the Signalfilt5_df (Signal Phasing data) and the TrCountmerged5_df (Traffic Volume data)\n",
    "\n",
    "Newmerged7_df = Signalfilt5_df.merge(TrCountmerged5_df, on='Combined_DateTime')\n",
    "Newmerged7_df\n",
    "\n",
    "# Rename the dataframe\n",
    "new_df_name = f\"site{site_id}_date{date_value}\"\n",
    "renamed_df = Newmerged7_df.copy()\n",
    "renamed_df.name = new_df_name\n",
    "\n",
    "\n",
    "# Specify the path and filename for the CSV file\n",
    "Newmerged7 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Output/str(data_value)/renamed.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#Newmerged6_df.to_csv(Newmerged6, index=False)\n",
    "#Newmerged6_df\n",
    "\n",
    "# Save the renamed dataframe to a CSV file\n",
    "csv_filename = f\"{new_df_name}.csv\"\n",
    "renamed_df.to_csv(renamed, index=False)\n",
    "\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#Newmerged7_df.to_csv(Newmerged7, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
