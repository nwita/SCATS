{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scats Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date  Site_ID  Cycle_sequence    Cycle_ starttime  \\\n",
      "67     2023-08-03     2368               1 2023-06-01 00:00:00   \n",
      "579    2023-08-03     2368               6 2023-06-01 00:05:00   \n",
      "1093   2023-08-03     2368              11 2023-06-01 00:10:00   \n",
      "1609   2023-08-03     2368              16 2023-06-01 00:15:00   \n",
      "2122   2023-08-03     2368              21 2023-06-01 00:20:00   \n",
      "...           ...      ...             ...                 ...   \n",
      "125877 2023-08-03     2368            1000 2023-06-01 23:35:00   \n",
      "126389 2023-08-03     2368            1005 2023-06-01 23:40:00   \n",
      "126897 2023-08-03     2368            1010 2023-06-01 23:45:00   \n",
      "127405 2023-08-03     2368            1015 2023-06-01 23:50:00   \n",
      "127919 2023-08-03     2368            1020 2023-06-01 23:55:00   \n",
      "\n",
      "          Combined_DateTime  Planned_ cyclelength  Actual_ cyclelength  \\\n",
      "67      2023-08-03 00:00:00                    60                   60   \n",
      "579     2023-08-03 00:05:00                    60                   60   \n",
      "1093    2023-08-03 00:10:00                    60                   60   \n",
      "1609    2023-08-03 00:15:00                    60                   60   \n",
      "2122    2023-08-03 00:20:00                    60                   60   \n",
      "...                     ...                   ...                  ...   \n",
      "125877  2023-08-03 23:35:00                    60                   60   \n",
      "126389  2023-08-03 23:40:00                    60                   60   \n",
      "126897  2023-08-03 23:45:00                    60                   60   \n",
      "127405  2023-08-03 23:50:00                    60                   60   \n",
      "127919  2023-08-03 23:55:00                    60                   60   \n",
      "\n",
      "        Required_ cyclelength  DS  Strategic_ approach_control_cy_time  \\\n",
      "67                         60  16                                   20   \n",
      "579                        60  27                                   20   \n",
      "1093                       60  29                                   20   \n",
      "1609                       60  28                                   21   \n",
      "2122                       60  28                                   24   \n",
      "...                       ...  ..                                  ...   \n",
      "125877                     60  71                                   20   \n",
      "126389                     60  43                                   22   \n",
      "126897                     60  54                                   22   \n",
      "127405                     60  40                                   20   \n",
      "127919                     60  30                                   20   \n",
      "\n",
      "        Subsystem_No Stretched_ phase      A    B    C      D     E     F   G  \\\n",
      "67                 6                A  178.0  1.0  1.0   17.0  19.0  14.0 NaN   \n",
      "579                6                A  176.0  1.0  1.0   19.0  19.0  14.0 NaN   \n",
      "1093               6                A  176.0  1.0  1.0   19.0  19.0  14.0 NaN   \n",
      "1609               6                A  176.0  1.0  1.0   19.0  19.0  14.0 NaN   \n",
      "2122               6                A  178.0  1.0  1.0   17.0  19.0  14.0 NaN   \n",
      "...              ...              ...    ...  ...  ...    ...   ...   ...  ..   \n",
      "125877             6                D   22.0  1.0  1.0  173.0  19.0  14.0 NaN   \n",
      "126389             6                D   22.0  1.0  1.0  173.0  19.0  14.0 NaN   \n",
      "126897             6                D   22.0  1.0  1.0  173.0  19.0  14.0 NaN   \n",
      "127405             6                D   22.0  1.0  1.0  173.0  19.0  14.0 NaN   \n",
      "127919             6                D   22.0  1.0  1.0  173.0  19.0  14.0 NaN   \n",
      "\n",
      "              Rounded_Time  \n",
      "67     2023-06-01 00:00:00  \n",
      "579    2023-06-01 00:05:00  \n",
      "1093   2023-06-01 00:10:00  \n",
      "1609   2023-06-01 00:15:00  \n",
      "2122   2023-06-01 00:20:00  \n",
      "...                    ...  \n",
      "125877 2023-06-01 23:35:00  \n",
      "126389 2023-06-01 23:40:00  \n",
      "126897 2023-06-01 23:45:00  \n",
      "127405 2023-06-01 23:50:00  \n",
      "127919 2023-06-01 23:55:00  \n",
      "\n",
      "[288 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_79160\\2165667536.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Signalfilt_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Read the 2 CSV files as dataframe and list the name of the columns\n",
    "Signaldf = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.SM.csv')\n",
    "\n",
    "Signaldf\n",
    "  \n",
    "# Convert 'Cycle_starttime' and 'Date' columns to datetime format\n",
    "\n",
    "Signaldf['Cycle_ starttime'] = pd.to_datetime(Signaldf['Cycle_ starttime'])\n",
    "\n",
    "Signaldf['Date'] = pd.to_datetime(Signaldf['Date'])\n",
    "\n",
    "# Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "Signaldf['Rounded_Time'] = Signaldf['Cycle_ starttime'].dt.floor('5T')\n",
    "\n",
    "# Create a new column by combining the 'Date' column and the rounded time\n",
    "#Signaldf['Combined_DateTime'] = pd.to_datetime(Signaldf['Date']) + Signaldf['Rounded_Time'].dt.time\n",
    "\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Date'].astype(str) + ' ' + Signaldf['Rounded_Time'].dt.time.astype(str)\n",
    "\n",
    "# Round down the 'Combined_DateTime' column to the nearest 5 minutes\n",
    "#Signaldf['Combined_DateTime'] = Signaldf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "Signaldf = Signaldf.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "\n",
    "# Move the 'Combined_DateTime' column to be the 5th column\n",
    "cols = list(Signaldf.columns)\n",
    "cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "Signaldf = Signaldf[cols]\n",
    "\n",
    "#Filter the rows in the 'Signaldf' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "Signalfilt_df = Signaldf[Signaldf['Site_ID'] == 2368]\n",
    "\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "Signalfilt_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(Signalfilt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Site_ID          Start_time  Traffic_Volume  Error  \\\n",
      "0     8/03/2023     2368 2023-06-01 00:00:00               4  False   \n",
      "24    8/03/2023     2368 2023-06-01 00:05:00              13  False   \n",
      "48    8/03/2023     2368 2023-06-01 00:10:00              19  False   \n",
      "72    8/03/2023     2368 2023-06-01 00:15:00               4  False   \n",
      "96    8/03/2023     2368 2023-06-01 00:20:00               6  False   \n",
      "...         ...      ...                 ...             ...    ...   \n",
      "6792  8/03/2023     2368 2023-06-01 23:35:00               6  False   \n",
      "6816  8/03/2023     2368 2023-06-01 23:40:00               7  False   \n",
      "6840  8/03/2023     2368 2023-06-01 23:45:00               5  False   \n",
      "6864  8/03/2023     2368 2023-06-01 23:50:00               4  False   \n",
      "6888  8/03/2023     2368 2023-06-01 23:55:00               3  False   \n",
      "\n",
      "       Combined_DateTime  2368-1  2368-10  2368-11  2368-12  ...  2368-22  \\\n",
      "0    2023-08-03 00:00:00       4        7       23       27  ...       85   \n",
      "24   2023-08-03 00:05:00      13        4       17       16  ...       32   \n",
      "48   2023-08-03 00:10:00      19        8       12       21  ...       35   \n",
      "72   2023-08-03 00:15:00       4        3       22        7  ...       33   \n",
      "96   2023-08-03 00:20:00       6        4       10       12  ...       29   \n",
      "...                  ...     ...      ...      ...      ...  ...      ...   \n",
      "6792 2023-08-03 23:35:00       6        3       16        8  ...       37   \n",
      "6816 2023-08-03 23:40:00       7        4        8        9  ...       50   \n",
      "6840 2023-08-03 23:45:00       5        4       13        7  ...       64   \n",
      "6864 2023-08-03 23:50:00       4        0        8        8  ...       50   \n",
      "6888 2023-08-03 23:55:00       3        3        4        9  ...       72   \n",
      "\n",
      "      2368-23  2368-24  2368-3  2368-4  2368-5  2368-6  2368-7  2368-8  2368-9  \n",
      "0           2        1      11      16       0      20     120      23       9  \n",
      "24          4        0       8      13       0       6      30      17      13  \n",
      "48          1        0      12       8       0       4      28      20       8  \n",
      "72          5        1       9      15       0       3      24      23      10  \n",
      "96         10        1       8      11       0       3      25      18       6  \n",
      "...       ...      ...     ...     ...     ...     ...     ...     ...     ...  \n",
      "6792        2        1       6      13       0      18      38      27       8  \n",
      "6816        2        4       4      12       0      23      62      10      10  \n",
      "6840        0        2       1      10       0       3      86      15       6  \n",
      "6864        0        0       5      11       0       6      69      13      14  \n",
      "6888        1        0       5      11       0       1      75      21      11  \n",
      "\n",
      "[288 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "TraffCountCHKdf = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.VS.csv')\n",
    "TraffCountCHKdf\n",
    "\n",
    "\n",
    "# Convert 'Start_time' column to datetime format\n",
    "TraffCountCHKdf['Start_time'] = pd.to_datetime(TraffCountCHKdf['Start_time'])\n",
    "\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHKdf['Combined_DateTime'] = TraffCountCHKdf['Date'].astype(str) + ' ' + TraffCountCHKdf['Start_time'].dt.time.astype(str)\n",
    "\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHKdf['Combined_DateTime'] = pd.to_datetime(TraffCountCHKdf['Combined_DateTime'])\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHKdf['Rounded_Combined_DateTime'] = TraffCountCHKdf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "#Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "filtered_df = TraffCountCHKdf[TraffCountCHKdf['Site_ID'] == 2368]\n",
    "\n",
    "# Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "pivoted_df = filtered_df.pivot(index=['Combined_DateTime', 'Site_ID'], columns='Detector_ID', values='Traffic_Volume')\n",
    "\n",
    "# Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "# Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "merged_df = filtered_df.merge(pivoted_df, on=['Combined_DateTime', 'Site_ID'], how='left')\n",
    "\n",
    "# Remove the 'Combined_DateTime' column\n",
    "merged_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "merged_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "\n",
    "# Drop the 'Detector_ID' column\n",
    "merged_df.drop('Detector_ID', axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "merged_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "TraffCountCHKdf = pd.read_csv('....../WEST_20230308.VS.csv')\n",
    "\n",
    "# Convert 'Start_time' column to datetime format\n",
    "TraffCountCHKdf['Start_time'] = pd.to_datetime(TraffCountCHKdf['Start_time'])\n",
    "\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHKdf['Combined_DateTime'] = TraffCountCHKdf['Date'].astype(str) + ' ' + TraffCountCHKdf['Start_time'].dt.time.astype(str)\n",
    "\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHKdf['Combined_DateTime'] = pd.to_datetime(TraffCountCHKdf['Combined_DateTime'])\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHKdf['Rounded_Combined_DateTime'] = TraffCountCHKdf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "# Filter the rows in the 'TraffCountCHKdf' DataFrame where the 'Site_ID' column has the value \"2368\"\n",
    "filtered_df = TraffCountCHKdf[TraffCountCHKdf['Site_ID'] == 2368]\n",
    "\n",
    "# Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "pivoted_df = filtered_df.pivot(index=['Combined_DateTime', 'Site_ID'], columns='Detector_ID', values='Traffic_Volume')\n",
    "\n",
    "# Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "# Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "merged_df = filtered_df.merge(pivoted_df, on=['Combined_DateTime', 'Site_ID'], how='left')\n",
    "\n",
    "# Drop the 'Start_time' column\n",
    "merged_df.drop('Start_time', axis=1, inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (288) does not match length of index (478656)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nsdsc0\\OneDrive - WSP O365\\DATA_ANALYTICS\\Python\\SCATS\\ScatsCHK.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/ScatsCHK.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Add the unique values of 'Detector_ID' as separate columns in 'TraffCount3df'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/ScatsCHK.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m detector_id \u001b[39min\u001b[39;00m TraffCountCHKdf[\u001b[39m'\u001b[39m\u001b[39mDetector_ID\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/ScatsCHK.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     TraffCountCHKdf[detector_id] \u001b[39m=\u001b[39m pivot_table\u001b[39m.\u001b[39mloc[:, TraffCountCHKdf[\u001b[39m'\u001b[39m\u001b[39mSite_ID\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/ScatsCHK.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Print the updated DataFrame\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/ScatsCHK.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(TraffCountCHKdf)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4534\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4535\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4536\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (288) does not match length of index (478656)"
     ]
    }
   ],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdfimport pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "TraffCountCHKdf = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.VS.csv')\n",
    "TraffCountCHKdf\n",
    "\n",
    "\n",
    "# Convert 'Start_time' column to datetime format\n",
    "TraffCountCHKdf['Start_time'] = pd.to_datetime(TraffCountCHKdf['Start_time'])\n",
    "\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHKdf['Combined_DateTime'] = TraffCountCHKdf['Date'].astype(str) + ' ' + TraffCountCHKdf['Start_time'].dt.time.astype(str)\n",
    "\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHKdf['Combined_DateTime'] = pd.to_datetime(TraffCountCHKdf['Combined_DateTime'])\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHKdf['Rounded_Combined_DateTime'] = TraffCountCHKdf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "#Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "filtered_df = TraffCountCHKdf[TraffCountCHKdf['Site_ID'] == 2368]\n",
    "\n",
    "# Create a pivot table with 'Start_time' as index, 'Site_ID' as columns, and 'Detector_ID' as values\n",
    "pivot_table = pd.pivot_table(TraffCountCHKdf, values='Traffic_Volume', index='Start_time', columns='Site_ID', aggfunc='first')\n",
    "\n",
    "# Add the unique values of 'Detector_ID' as separate columns in 'TraffCount3df'\n",
    "for detector_id in TraffCountCHKdf['Detector_ID'].unique():\n",
    "    TraffCountCHKdf[detector_id] = pivot_table.loc[:, TraffCountCHKdf['Site_ID']].values\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(TraffCountCHKdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdf\n",
    "\n",
    "# Create a pivot table with 'Start_time' as index, 'Site_ID' as columns, and 'Detector_ID' as values\n",
    "pivot_table = pd.pivot_table(TraffCountCHKdf, values='Traffic_Volume', index='Start_time', columns='Site_ID', aggfunc='first')\n",
    "\n",
    "# Add the unique values of 'Detector_ID' as separate columns in 'TraffCount3df'\n",
    "for detector_id in TraffCount3df['Detector_ID'].unique():\n",
    "    TraffCount3df[detector_id] = pivot_table.loc[:, TraffCount3df['Site_ID']].values\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(TraffCount3df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdf\n",
    "# Get unique values of 'Detector_ID' column\n",
    "unique_detector_ids = TraffCount3df['Detector_ID'].unique()\n",
    "\n",
    "# Create new columns for each unique detector ID\n",
    "for detector_id in unique_detector_ids:\n",
    "    TraffCount3df[detector_id] = 0\n",
    "\n",
    "# Iterate over the rows and update the corresponding detector ID column with traffic volume\n",
    "for index, row in TraffCount3df.iterrows():\n",
    "    detector_id = row['Detector_ID']\n",
    "    TraffCount3df.loc[index, detector_id] = row['Traffic_Volume']\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(TraffCount3df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the 'Date' and 'Start_time' columns\n",
    "TraffCount3df['Combined_DateTime'] = pd.to_datetime(TraffCount3df['Date'] + ' ' + TraffCount3df['Start_time'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(TraffCount3df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for TraffCountCHKdf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'TraffCount3df' is your DataFrame containing the 'Start_time' and 'Date' columns\n",
    "# Convert 'Start_time' column to datetime format\n",
    "TraffCount3df['Start_time'] = pd.to_datetime(TraffCount3df['Start_time'])\n",
    "\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCount3df['Combined_DateTime'] = TraffCount3df['Date'].astype(str) + ' ' + TraffCount3df['Start_time'].dt.time.astype(str)\n",
    "\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCount3df['Combined_DateTime'] = pd.to_datetime(TraffCount3df['Combined_DateTime'])\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCount3df['Rounded_Combined_DateTime'] = TraffCount3df['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(TraffCount3df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "\n",
    "#This code assumes that you have already imported the pandas library and that the 'Signaldf' DataFrame is already defined with the columns 'Cycle_ starttime' and 'Date'. \n",
    "#The code adds three new columns: 'Rounded_Time', 'Combined_DateTime', and 'Combined_DateTime' (renamed from 'Rounded_Combined_DateTime'). \n",
    "#It also moves the 'Combined_DateTime' column to be the 5th column in the DataFrame.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Round the 'Cycle_ starttime' column into 5 minutes intervals\n",
    "Signaldf['Rounded_Time'] = pd.to_datetime(Signaldf['Cycle_ starttime']).dt.floor('5min')\n",
    "\n",
    "# Create a new column by combining the 'Date' column and the rounded time\n",
    "Signaldf['Combined_DateTime'] = pd.to_datetime(Signaldf['Date']) + Signaldf['Rounded_Time'].dt.time\n",
    "\n",
    "# Round down the 'Combined_DateTime' column to the nearest 5 minutes\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "Signaldf = Signaldf.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "\n",
    "# Move the 'Combined_DateTime' column to be the 5th column\n",
    "cols = list(Signaldf.columns)\n",
    "cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "Signaldf = Signaldf[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Round 'Cycle_ starttime' to 5 minutes intervals\n",
    "Signaldf['Rounded_Cycle_starttime'] = Signaldf['Cycle_ starttime'].dt.floor('5min')\n",
    "\n",
    "# Combine 'Date' and rounded time\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Date'] + timedelta(hours=Signaldf['Rounded_Cycle_starttime'].dt.hour,\n",
    "                                                             minutes=Signaldf['Rounded_Cycle_starttime'].dt.minute)\n",
    "\n",
    "# Round 'Combined_DateTime' down to the nearest 5 minutes\n",
    "Signaldf['Rounded_Combined_DateTime'] = Signaldf['Combined_DateTime'].dt.floor('5min')\n",
    "\n",
    "# Rename 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "Signaldf = Signaldf.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "\n",
    "# Move 'Combined_DateTime' column to the 5th position\n",
    "cols = list(Signaldf.columns)\n",
    "cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "Signaldf = Signaldf[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming 'Signaldf' is your DataFrame containing the 'Cycle_ starttime' and 'Date' columns\n",
    "# Convert 'Cycle_ starttime' column to datetime format\n",
    "Signaldf['Cycle_ starttime'] = pd.to_datetime(Signaldf['Cycle_ starttime'])\n",
    "\n",
    "# Round 'Cycle_ starttime' to the nearest 5 minutes using dt.floor\n",
    "Signaldf['Rounded_Time'] = Signaldf['Cycle_ starttime'].dt.floor('5min')\n",
    "\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Date'].astype(str) + ' ' + Signaldf['Rounded_Time'].dt.time.astype(str)\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "Signaldf['Rounded_Combined_DateTime'] = pd.to_datetime(Signaldf['Combined_DateTime']).dt.floor('5min')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming 'Signaldf' is your DataFrame containing the 'Cycle_ starttime' and 'Date' columns\n",
    "# Convert 'Cycle_ starttime' column to datetime format\n",
    "Signaldf['Cycle_ starttime'] = pd.to_datetime(Signaldf['Cycle_ starttime'])\n",
    "\n",
    "# Round 'Cycle_ starttime' to the nearest 5 minutes using dt.floor\n",
    "Signaldf['Rounded_Time'] = Signaldf['Cycle_ starttime'].dt.floor('5min')\n",
    "\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Date'].astype(str) + ' ' + Signaldf['Rounded_Time'].dt.time.astype(str)\n",
    "\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "Signaldf['Rounded_Combined_DateTime'] = pd.to_datetime(Signaldf['Combined_DateTime']).dt.floor('5min')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "import pandas as pd\n",
    "\n",
    "# Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "Signaldf['Rounded_Time'] = Signaldf['Cycle_starttime'].dt.floor('5T')\n",
    "\n",
    "# Combine the 'Date' column and the rounded time\n",
    "Signaldf['Combined_DateTime'] = Signaldf['Date'].astype(str) + ' ' + Signaldf['Rounded_Time'].dt.time.astype(str)\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'Signaldf' is your DataFrame and 'Cycle_ starttime' is the column of interest\n",
    "\n",
    "# Convert 'Cycle_ starttime' to datetime type if it's not already\n",
    "Signaldf['Cycle_ starttime'] = pd.to_datetime(Signaldf['Cycle_ starttime'])\n",
    "\n",
    "# Round the 'Cycle_ starttime' to the nearest 5-minute interval. THIS IS THE OLD CODE given by chatGPT '5Min'\n",
    "Signaldf['Rounded starttime'] = Signaldf['Cycle_ starttime'].dt.floor('5Min')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming 'Signaldf' is your DataFrame with the 'Cycle_ starttime' column\n",
    "# Create a sample DataFrame for demonstration\n",
    "data = {\n",
    "    'Cycle_starttime': ['00:01:00', '00:02:00', '00:03:00', '00:04:00', '00:06:00', '00:07:00', '00:09:00']\n",
    "}\n",
    "Signaldf = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'Cycle_starttime' column to datetime format\n",
    "Signaldf['Cycle_starttime'] = pd.to_datetime(Signaldf['Cycle_starttime'])\n",
    "\n",
    "# Round the 'Cycle_starttime' column to 5-minute intervals\n",
    "Signaldf['Rounded_starttime'] = Signaldf['Cycle_starttime'].apply(lambda x: (x - timedelta(minutes=x.minute % 5)) + timedelta(minutes=5))\n",
    "\n",
    "# Convert 'Rounded_starttime' column back to string format\n",
    "Signaldf['Rounded_starttime'] = Signaldf['Rounded_starttime'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FOR YOUR CHECK OLD CODES as I was building up the top cell for Signaldf\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming 'Signaldf' is your DataFrame with the 'Cycle_starttime' and 'Date' columns\n",
    "# Create a sample DataFrame for demonstration\n",
    "data = {\n",
    "    'Cycle_starttime': ['00:01:00', '00:02:00', '00:03:00', '00:04:00', '00:06:00', '00:07:00', '00:09:00'],\n",
    "    'Date': ['2023-05-31', '2023-05-31', '2023-05-31', '2023-05-31', '2023-05-31', '2023-05-31', '2023-05-31']\n",
    "}\n",
    "Signaldf = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "# Round the 'Cycle_starttime' column to 5-minute intervals\n",
    "Signaldf['Rounded_starttime'] = Signaldf.apply(lambda row: (row['Cycle_starttime'] - timedelta(minutes=row['Cycle_starttime'].minute % 5)) + timedelta(minutes=5), axis=1)\n",
    "\n",
    "# Combine 'Date' and 'Rounded_starttime' columns and convert to string format\n",
    "Signaldf['Rounded_starttime'] = Signaldf['Rounded_starttime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(Signaldf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TraffCount3df = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.VS.csv')\n",
    "Traffic_column = TraffCount3df.columns.tolist()\n",
    "# Print the column names\n",
    "for column in Traffic_column:\n",
    " print(column)\n",
    " print(TraffCount3df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = TraffCount3df[TraffCount3df['Site_ID'] == '2368']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "TraffCount2df['Date'] = pd.to_datetime(TraffCount2df['Date'])\n",
    "\n",
    "# Convert 'Start_time' column to datetime\n",
    "TraffCount2df['Start_time'] = pd.to_datetime(TraffCount2df['Start_time'], format='%H:%M:%S')\n",
    "\n",
    "# Modify the format of 'Start_time' column\n",
    "TraffCount2df['Start_time'] = TraffCount2df['Start_time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Create a new column combining 'Date' and 'Start_time'\n",
    "TraffCount2df['Combined_datetime'] = TraffCount2df['Date'].astype(str) + ' ' + TraffCount2df['Start_time']\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "print(TraffCount2df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the corresponding Detector_Ids\n",
    "filt_detec_ids = TraffCount2df.loc[TraffCount2df['Site_ID'] == 2368, 'Detector_ID']\n",
    "\n",
    "# Create new columns with extracted Detector_Ids\n",
    "for Detector_Id in filt_detec_ids:\n",
    "    TraffCount2df[Detector_Id] = None  # Initialize the new column with None\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "# print(TraffCount2df)\n",
    "\n",
    "# Define a custom function to fill the Detector Id columns\n",
    "def fill_traffic_volume(row):\n",
    "    site_id = row['Site_ID']\n",
    "    start_time = row['Start_time']\n",
    "    traffic_volume = row['Traffic_Volume']\n",
    "\n",
    "    # Iterate over the filtered Detector Ids for Site ID 2368\n",
    "    for detector_id in filt_detec_ids:\n",
    "        if (row['Detector_ID'] == detector_id) and (row['Site_ID'] == site_id):\n",
    "            return traffic_volume\n",
    "\n",
    "    return None  # Return None if no matching Detector Id is found\n",
    "\n",
    "# Apply the custom function to fill the Detector Id columns\n",
    "for detector_id in filt_detec_ids:\n",
    "    TraffCount2df[detector_id] = TraffCount2df.apply(fill_traffic_volume, axis=1)\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "print(TraffCount2df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
