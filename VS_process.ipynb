{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site ID</th>\n",
       "      <th>Detector ID</th>\n",
       "      <th>Start time</th>\n",
       "      <th>Traffic volume</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/03/2023</td>\n",
       "      <td>2366</td>\n",
       "      <td>2366-1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/03/2023</td>\n",
       "      <td>2366</td>\n",
       "      <td>2366-2</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/03/2023</td>\n",
       "      <td>2366</td>\n",
       "      <td>2366-3</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/03/2023</td>\n",
       "      <td>2366</td>\n",
       "      <td>2366-4</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/03/2023</td>\n",
       "      <td>2366</td>\n",
       "      <td>2366-5</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435963</th>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>3112</td>\n",
       "      <td>3112-6</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435964</th>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>3112</td>\n",
       "      <td>3112-17</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435965</th>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>3112</td>\n",
       "      <td>3112-18</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435966</th>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>3112</td>\n",
       "      <td>3112-19</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435967</th>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>3112</td>\n",
       "      <td>3112-20</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1435968 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date  Site ID Detector ID Start time  Traffic volume  Error\n",
       "0         8/03/2023     2366      2366-1   00:00:00               0  False\n",
       "1         8/03/2023     2366      2366-2   00:00:00               5  False\n",
       "2         8/03/2023     2366      2366-3   00:00:00               1  False\n",
       "3         8/03/2023     2366      2366-4   00:00:00               1  False\n",
       "4         8/03/2023     2366      2366-5   00:00:00               0  False\n",
       "...             ...      ...         ...        ...             ...    ...\n",
       "1435963  10/03/2023     3112      3112-6   23:55:00               4  False\n",
       "1435964  10/03/2023     3112     3112-17   23:55:00               2  False\n",
       "1435965  10/03/2023     3112     3112-18   23:55:00               0  False\n",
       "1435966  10/03/2023     3112     3112-19   23:55:00               1  False\n",
       "1435967  10/03/2023     3112     3112-20   23:55:00               0  False\n",
       "\n",
       "[1435968 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "folder_path = 'Samples for WSP/VS/'\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dataframes1 = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df1 = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes1.append(df1)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "combined_df1 = pd.concat(dataframes1, ignore_index=True)\n",
    "\n",
    "# # # Create the output folder if it doesn't exist\n",
    "# output_folder = 'output'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "combined_df1['Date'].unique()\n",
    "combined_df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_26648\\52918869.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TraffCountCHK6df['Start time'] = pd.to_datetime(TraffCountCHK6df['Start time'])\n",
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_26648\\52918869.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TraffCountCHK6df['Combined_DateTime'] = TraffCountCHK6df['Date'].astype(str) + ' ' + TraffCountCHK6df['Start time'].dt.time.astype(str)\n",
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_26648\\52918869.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TraffCountCHK6df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK6df['Combined_DateTime'])\n",
      "C:\\Users\\nsdsc0\\AppData\\Local\\Temp\\ipykernel_26648\\52918869.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TraffCountCHK6df['Rounded_Combined_DateTime'] = TraffCountCHK6df['Combined_DateTime'].dt.floor('5min')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nsdsc0\\OneDrive - WSP O365\\DATA_ANALYTICS\\Python\\SCATS\\VS_process.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/VS_process.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m filtered6_df \u001b[39m=\u001b[39m TraffCountCHK6df[TraffCountCHK6df[\u001b[39m'\u001b[39m\u001b[39mSite ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m site_id]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/VS_process.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Pivot the DataFrame to create separate columns for each unique Detector_ID\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/VS_process.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m pivoted6_df \u001b[39m=\u001b[39m filtered6_df\u001b[39m.\u001b[39;49mpivot(index\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mCombined_DateTime\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSite ID\u001b[39;49m\u001b[39m'\u001b[39;49m], columns\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mDetector ID\u001b[39;49m\u001b[39m'\u001b[39;49m, values\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraffic volume\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/VS_process.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Reset the index to make the combined DateTime and Site_ID columns regular columns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/VS_process.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m pivoted6_df \u001b[39m=\u001b[39m pivoted6_df\u001b[39m.\u001b[39mreset_index()\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:7882\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   7877\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   7878\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   7879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot\u001b[39m(\u001b[39mself\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, values\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   7880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot\n\u001b[1;32m-> 7882\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot(\u001b[39mself\u001b[39;49m, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, values\u001b[39m=\u001b[39;49mvalues)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:520\u001b[0m, in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m         indexed \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_constructor_sliced(data[values]\u001b[39m.\u001b[39m_values, index\u001b[39m=\u001b[39mmultiindex)\n\u001b[1;32m--> 520\u001b[0m \u001b[39mreturn\u001b[39;00m indexed\u001b[39m.\u001b[39;49munstack(columns_listlike)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4157\u001b[0m, in \u001b[0;36mSeries.unstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   4114\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4115\u001b[0m \u001b[39mUnstack, also known as pivot, Series with MultiIndex to produce DataFrame.\u001b[39;00m\n\u001b[0;32m   4116\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4153\u001b[0m \u001b[39mb    2    4\u001b[39;00m\n\u001b[0;32m   4154\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m \u001b[39mimport\u001b[39;00m unstack\n\u001b[1;32m-> 4157\u001b[0m \u001b[39mreturn\u001b[39;00m unstack(\u001b[39mself\u001b[39;49m, level, fill_value)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:491\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39mif\u001b[39;00m is_1d_only_ea_dtype(obj\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m _unstack_extension_series(obj, level, fill_value)\n\u001b[1;32m--> 491\u001b[0m unstacker \u001b[39m=\u001b[39m _Unstacker(\n\u001b[0;32m    492\u001b[0m     obj\u001b[39m.\u001b[39;49mindex, level\u001b[39m=\u001b[39;49mlevel, constructor\u001b[39m=\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor_expanddim\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m unstacker\u001b[39m.\u001b[39mget_result(\n\u001b[0;32m    495\u001b[0m     obj\u001b[39m.\u001b[39m_values, value_columns\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fill_value\u001b[39m=\u001b[39mfill_value\n\u001b[0;32m    496\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:140\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mif\u001b[39;00m num_cells \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:\n\u001b[0;32m    134\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    135\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following operation may generate \u001b[39m\u001b[39m{\u001b[39;00mnum_cells\u001b[39m}\u001b[39;00m\u001b[39m cells \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the resulting pandas object.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m         PerformanceWarning,\n\u001b[0;32m    138\u001b[0m     )\n\u001b[1;32m--> 140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_selectors()\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:177\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    174\u001b[0m new_levels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_index_levels\n\u001b[0;32m    176\u001b[0m \u001b[39m# make the mask\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m remaining_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msorted_labels[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    178\u001b[0m level_sizes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m new_levels)\n\u001b[0;32m    180\u001b[0m comp_index, obs_ids \u001b[39m=\u001b[39m get_compressed_ids(remaining_labels, level_sizes)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:164\u001b[0m, in \u001b[0;36m_Unstacker.sorted_labels\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[0;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msorted_labels\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 164\u001b[0m     indexer, to_sort \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indexer_and_to_sort\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m [line\u001b[39m.\u001b[39mtake(indexer) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m to_sort]\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:156\u001b[0m, in \u001b[0;36m_Unstacker._indexer_and_to_sort\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    153\u001b[0m to_sort \u001b[39m=\u001b[39m codes[:v] \u001b[39m+\u001b[39m codes[v \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :] \u001b[39m+\u001b[39m [codes[v]]\n\u001b[0;32m    154\u001b[0m sizes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mlen\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m levs[:v] \u001b[39m+\u001b[39m levs[v \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :] \u001b[39m+\u001b[39m [levs[v]])\n\u001b[1;32m--> 156\u001b[0m comp_index, obs_ids \u001b[39m=\u001b[39m get_compressed_ids(to_sort, sizes)\n\u001b[0;32m    157\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(obs_ids)\n\u001b[0;32m    159\u001b[0m indexer \u001b[39m=\u001b[39m get_group_index_sorter(comp_index, ngroups)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\sorting.py:214\u001b[0m, in \u001b[0;36mget_compressed_ids\u001b[1;34m(labels, sizes)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_compressed_ids\u001b[39m(\n\u001b[0;32m    195\u001b[0m     labels, sizes: Shape\n\u001b[0;32m    196\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mint64]]:\n\u001b[0;32m    197\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m    Group_index is offsets into cartesian product of all possible labels. This\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m    space can be huge, so this function compresses it, by computing offsets\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m        obs_group_ids\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     ids \u001b[39m=\u001b[39m get_group_index(labels, sizes, sort\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, xnull\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    215\u001b[0m     \u001b[39mreturn\u001b[39;00m compress_group_index(ids, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\sorting.py:168\u001b[0m, in \u001b[0;36mget_group_index\u001b[1;34m(labels, shape, sort, xnull)\u001b[0m\n\u001b[0;32m    165\u001b[0m stride \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mprod(lshape[\u001b[39m1\u001b[39m:nlev], dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m out \u001b[39m=\u001b[39m stride \u001b[39m*\u001b[39m labels[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 168\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m, nlev):\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m lshape[i] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    170\u001b[0m         stride \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint64(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over each unique date in the \"Date\" column\n",
    "for date in combined_df1['Date'].unique():\n",
    "    # Replace \"/\" with \"-\" in the date\n",
    "    formatted_date1 = date.replace(\"/\", \"-\")\n",
    "        # # Create a folder for the current date\n",
    "    # date_folder = os.path.join(output_folder, formatted_date)\n",
    "    # os.makedirs(date_folder, exist_ok=True)\n",
    "    TraffCountCHK7df = combined_df1[combined_df1['Date'] == date]\n",
    "    # Convert 'Start_time' column in Traffic Count data to datetime format\n",
    "    TraffCountCHK7df['Start time'] = pd.to_datetime(TraffCountCHK7df['Start time'])\n",
    "            # Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "    TraffCountCHK7df['Combined_DateTime'] = TraffCountCHK7df['Date'].astype(str) + ' ' + TraffCountCHK7df['Start time'].dt.time.astype(str)\n",
    "    # Convert 'Combined_DateTime' column to datetime format\n",
    "    TraffCountCHK7df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK7df['Combined_DateTime'])\n",
    "    # Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "    TraffCountCHK7df['Rounded_Combined_DateTime'] = TraffCountCHK7df['Combined_DateTime'].dt.floor('5min')\n",
    "    #Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "    for site_id in TraffCountCHK7df['Site ID'].unique():\n",
    "        site_idfilt7_df = TraffCountCHK7df[TraffCountCHK7df['Site ID'] == site_id]\n",
    "        # Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "        site_idpivot7_df = site_idfilt7_df.pivot(index=['Combined_DateTime', 'Site ID'], columns='Detector ID', values='Traffic volume')\n",
    "        # Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "        site_idpivot7_df = site_idpivot7_df.reset_index()\n",
    "        # Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "        site_idmerged7_df = site_idfilt7_df.merge(site_idpivot7_df, on=['Combined_DateTime', 'Site ID'], how='left')\n",
    "        # Remove the 'Combined_DateTime' column\n",
    "        site_idmerged7_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "        # Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "        site_idmerged7_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "        # Drop the 'Detector_ID' column\n",
    "        site_idmerged7_df.drop('Detector ID', axis=1, inplace=True)\n",
    "        # Remove duplicate values in the 'Combined_DateTime' column\n",
    "        site_idmerged7_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "        # Drop Cycle_starttime column\n",
    "        site_idmerged7_df = site_idmerged7_df.drop(['Start time', 'Traffic volume'], axis=1)\n",
    "        # Convert 'Combined_DateTime' column to datetime format\n",
    "        site_idmerged7_df['Combined_DateTime'] = pd.to_datetime(site_idmerged7_df['Combined_DateTime'])\n",
    "        # single_date_df_folder = output_folder+\"/\"+formatted_date+f\"/{site_idmerged7}.csv\"\n",
    "        # # Write the DataFrame to a CSV file\n",
    "        # site_idmerged7_df.to_csv(single_date_df_folder, index=False)            \n",
    "        # Print the updated DataFrame\n",
    "        site_idmerged7_df\n",
    "        # # Specify the path and filename for the CSV file\n",
    "        # TrCountmerged6 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/TrCountmerged6.csv\"\n",
    "        # # Write the DataFrame to a CSV file\n",
    "        # TrCountmerged6_df.to_csv(TrCountmerged6, index=False)\n",
    "        # TrCountmerged6_df\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
