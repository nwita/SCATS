{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scats Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "site_id = 2368\n",
    "\n",
    "Datapath: Path('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS')\n",
    "\n",
    "# Read the 2 CSV files for Signal Phasing and Traffic Count data.CSV file as dataframe \n",
    "Signal4df = pd.read_csv('WEST_20230308.SM.csv')\n",
    "Signal4df\n",
    "TraffCountCHK4df = pd.read_csv('WEST_20230308.VS.csv')\n",
    "TraffCountCHK4df\n",
    "\n",
    "# Cleaning and manipulating the data on Signal Phasing: \n",
    "\n",
    "# Convert 'Cycle_starttime' and 'Date' columns to datetime format\n",
    "#Signal4df['Cycle_ starttime'] = pd.to_datetime(Signal4df['Cycle_ starttime'])\n",
    "#Signal4df['Date'] = pd.to_datetime(Signal4df['Date'])\n",
    "# Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "#Signal4df['Rounded_Time'] = Signal4df['Cycle_ starttime'].dt.floor('5T')\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "#Signal4df['Combined_DateTime'] = Signal4df['Date'].astype(str) + ' ' + Signal4df['Rounded_Time'].dt.time.astype(str)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "#Signal4df = Signal4df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "# Move the 'Combined_DateTime' column to be the 5th column\n",
    "#cols = list(Signal4df.columns)\n",
    "#cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "#Signal4df = Signal4df[cols]\n",
    "#Filter the rows in the 'Signal3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "#Signalfilt4_df = Signal4df[Signal4df['Site_ID'] == site_id]\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "#Signalfilt4_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "#Signalfilt4_df = Signalfilt4_df.drop('Cycle_ starttime', axis=1)\n",
    "# Print the updated DataFrame\n",
    "#Signalfilt4_df\n",
    "# Specify the path and filename for the CSV file\n",
    "#Signalfilt4 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Signalfilt4.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "#Signalfilt4_df.to_csv(Signalfilt4, index=False)\n",
    "#Signalfilt4_df\n",
    "\n",
    "# Cleaning and manipulating the data on Traffic Count: \n",
    "\n",
    "# Convert 'Start_time' column in Traffic Count data to datetime format\n",
    "TraffCountCHK4df['Start_time'] = pd.to_datetime(TraffCountCHK4df['Start_time'])\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHK4df['Combined_DateTime'] = TraffCountCHK4df['Date'].astype(str) + ' ' + TraffCountCHK4df['Start_time'].dt.time.astype(str)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHK4df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK4df['Combined_DateTime'])\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHK4df['Rounded_Combined_DateTime'] = TraffCountCHK4df['Combined_DateTime'].dt.floor('5min')\n",
    "#Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "filtered4_df = TraffCountCHK4df[TraffCountCHK4df['Site_ID'] == site_id]\n",
    "# Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "pivoted4_df = filtered4_df.pivot(index=['Combined_DateTime', 'Site_ID'], columns='Detector_ID', values='Traffic_Volume')\n",
    "# Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "pivoted4_df = pivoted4_df.reset_index()\n",
    "# Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "TrCountmerged4_df = filtered4_df.merge(pivoted4_df, on=['Combined_DateTime', 'Site_ID'], how='left')\n",
    "# Remove the 'Combined_DateTime' column\n",
    "TrCountmerged4_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "TrCountmerged4_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "# Drop the 'Detector_ID' column\n",
    "TrCountmerged4_df.drop('Detector_ID', axis=1, inplace=True)\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "TrCountmerged4_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "TrCountmerged4_df = TrCountmerged4_df.drop(['Start_time', 'Traffic_Volume'], axis=1)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TrCountmerged4_df['Combined_DateTime'] = pd.to_datetime(TrCountmerged4_df['Combined_DateTime'])\n",
    "# Print the updated DataFrame\n",
    "TrCountmerged4_df\n",
    "# Specify the path and filename for the CSV file\n",
    "TrCountmerged4 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/TrCountmerged4.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "TrCountmerged4_df.to_csv(TrCountmerged4, index=False)\n",
    "TrCountmerged4_df\n",
    "\n",
    "# Convert datetime column to string in both dataframes\n",
    "Signalfilt4_df['Combined_DateTime'] = Signalfilt4_df['Combined_DateTime'].astype(str)\n",
    "TrCountmerged4_df['Combined_DateTime'] = TrCountmerged4_df['Combined_DateTime'].astype(str)\n",
    "\n",
    "# Merge the Signalfilt4_df (Signal Phasing data) and the merged4_df (Traffic Volume data)\n",
    "\n",
    "Newmerged6_df = Signalfilt4_df.merge(TrCountmerged4_df, on='Combined_DateTime')\n",
    "(Newmerged6_df)\n",
    "\n",
    "# Specify the path and filename for the CSV file\n",
    "#Newmerged6 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Newmerged6.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#Newmerged6_df.to_csv(Newmerged6, index=False)\n",
    "#Newmerged6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime column to string in both dataframes\n",
    "Signalfilt3_df['Combined_DateTime'] = Signalfilt3_df['Combined_DateTime'].astype(str)\n",
    "TrCountmerged3_df['Combined_DateTime'] = TrCountmerged3_df['Combined_DateTime'].astype(str)\n",
    "\n",
    "# Merge the Signalfilt3_df (Signal Phasing data) and the merged3_df (Traffic Volume data)\n",
    "\n",
    "Newmerged5_df = Signalfilt3_df.merge(TrCountmerged3_df, on='Combined_DateTime')\n",
    "print(Newmerged5_df)\n",
    "\n",
    "# Specify the path and filename for the CSV file\n",
    "Newmerged5 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Newmerged5.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "Newmerged5_df.to_csv(Newmerged5, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
