{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scats Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "site_id = 2368\n",
    "Datapath: Path('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS')\n",
    "\n",
    "# Create the 'Output' folder inside the Datapath\n",
    "output_folder = Path('Output')\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Read the 2 CSV files for Signal Phasing and Traffic Count data.CSV file as dataframe \n",
    "Signal6df = pd.read_csv('WEST_20230308.SM.csv') # read multiple file from a folder with For loop\n",
    "#Signal6df\n",
    "# Get the unique Site_ID values\n",
    "site_id_list = Signal6df['Site_ID'].unique().tolist()\n",
    "site_id_list\n",
    "# Get the unique date values\n",
    "date_value_list = Signal6df['Date'].unique().tolist()\n",
    "\n",
    "# Get the unique date values\n",
    "date_value_list = Signal6df['Date'].unique().tolist()\n",
    "\n",
    "# Create a folder for each unique date inside the 'Output' folder\n",
    "for date_value in date_value_list:\n",
    "    date_value = date_value.replace(\"/\",\"-\")\n",
    "    date_folder = Path(f'Output/{date_value}')  # Construct the path for the date folder\n",
    "    date_folder.mkdir(exist_ok=True)  # Create the date folder if it doesn't exist\n",
    "\n",
    "\n",
    "\n",
    "# TraffCountCHK6df = pd.read_csv('WEST_20230308.VS.csv')\n",
    "#TraffCountCHK6df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#Newmerged7_df.to_csv(Newmerged7, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and manipulating the data on Signal Phasing: \n",
    "\n",
    "# Convert 'Cycle_starttime' and 'Date' columns to datetime format\n",
    "Signal6df['Cycle_ starttime'] = pd.to_datetime(Signal6df['Cycle_ starttime'])\n",
    "Signal6df['Date'] = pd.to_datetime(Signal6df['Date'])\n",
    "# Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "Signal6df['Rounded_Time'] = Signal6df['Cycle_ starttime'].dt.floor('5T')\n",
    "# Combine 'Date' and 'Rounded_Time' into a new column\n",
    "Signal6df['Combined_DateTime'] = Signal6df['Date'].astype(str) + ' ' + Signal6df['Rounded_Time'].dt.time.astype(str)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "Signal6df = Signal6df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "# Move the 'Combined_DateTime' column to be the 5th column\n",
    "cols = list(Signal6df.columns)\n",
    "cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "Signal6df = Signal6df[cols]\n",
    "#Filter the rows in the 'Signal6df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "Signalfilt6_df = Signal6df[Signal6df['Site_ID'] == site_id]\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "Signalfilt6_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "Signalfilt6_df = Signalfilt6_df.drop('Cycle_ starttime', axis=1)\n",
    "# Print the updated DataFrame\n",
    "#Signalfilt6_df\n",
    "# Specify the path and filename for the CSV file\n",
    "Signalfilt6 = Path+\"/Signalfilt6.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "Signalfilt6_df.to_csv(Signalfilt6, index=False)\n",
    "Signalfilt6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and manipulating the data on Traffic Count: \n",
    "\n",
    "# Convert 'Start_time' column in Traffic Count data to datetime format\n",
    "TraffCountCHK6df['Start_time'] = pd.to_datetime(TraffCountCHK6df['Start_time'])\n",
    "# Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "TraffCountCHK6df['Combined_DateTime'] = TraffCountCHK6df['Date'].astype(str) + ' ' + TraffCountCHK6df['Start_time'].dt.time.astype(str)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TraffCountCHK6df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK6df['Combined_DateTime'])\n",
    "# Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "TraffCountCHK6df['Rounded_Combined_DateTime'] = TraffCountCHK6df['Combined_DateTime'].dt.floor('5min')\n",
    "#Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "filtered6_df = TraffCountCHK6df[TraffCountCHK6df['Site_ID'] == site_id]\n",
    "# Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "pivoted6_df = filtered6_df.pivot(index=['Combined_DateTime', 'Site_ID'], columns='Detector_ID', values='Traffic_Volume')\n",
    "# Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "pivoted6_df = pivoted6_df.reset_index()\n",
    "# Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "TrCountmerged6_df = filtered6_df.merge(pivoted6_df, on=['Combined_DateTime', 'Site_ID'], how='left')\n",
    "# Remove the 'Combined_DateTime' column\n",
    "TrCountmerged6_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "# Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "TrCountmerged6_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "# Drop the 'Detector_ID' column\n",
    "TrCountmerged6_df.drop('Detector_ID', axis=1, inplace=True)\n",
    "# Remove duplicate values in the 'Combined_DateTime' column\n",
    "TrCountmerged6_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "# Drop Cycle_starttime column\n",
    "TrCountmerged6_df = TrCountmerged6_df.drop(['Start_time', 'Traffic_Volume'], axis=1)\n",
    "# Convert 'Combined_DateTime' column to datetime format\n",
    "TrCountmerged6_df['Combined_DateTime'] = pd.to_datetime(TrCountmerged6_df['Combined_DateTime'])\n",
    "# Print the updated DataFrame\n",
    "TrCountmerged6_df\n",
    "# Specify the path and filename for the CSV file\n",
    "TrCountmerged6 = \"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/TrCountmerged6.csv\"\n",
    "# Write the DataFrame to a CSV file\n",
    "TrCountmerged6_df.to_csv(TrCountmerged6, index=False)\n",
    "TrCountmerged6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime column to string in both dataframes\n",
    "Signalfilt6_df['Combined_DateTime'] = Signalfilt6_df['Combined_DateTime'].astype(str)\n",
    "TrCountmerged6_df['Combined_DateTime'] = TrCountmerged6_df['Combined_DateTime'].astype(str)\n",
    "\n",
    "# Merge the Signalfilt6_df (Signal Phasing data) and the TrCountmerged6_df (Traffic Volume data)\n",
    "\n",
    "Newmerged9_df = Signalfilt6_df.merge(TrCountmerged6_df, on='Combined_DateTime')\n",
    "Newmerged9_df\n",
    "\n",
    "# Rename the dataframe\n",
    "new_df_name = f\"site{site_id}_date{date_value}\"\n",
    "renamed_df = Newmerged9_df.copy()\n",
    "renamed_df.name = new_df_name\n",
    "\n",
    "\n",
    "# Specify the path and filename for the CSV file\n",
    "Newmerged9 = f\"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Output/str(data_value)/{site_id}.csv\"\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "#Newmerged6_df.to_csv(Newmerged6, index=False)\n",
    "#Newmerged6_df\n",
    "\n",
    "# Save the renamed dataframe to a CSV file\n",
    "csv_filename = f\"{new_df_name}.csv\"\n",
    "renamed_df.to_csv(renamed, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
