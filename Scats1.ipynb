{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scats Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "Site_ID\n",
      "Cycle_sequence\n",
      "Cycle_ starttime\n",
      "Planned_ cyclelength\n",
      "Actual_ cyclelength\n",
      "Required_ cyclelength\n",
      "DS\n",
      "Strategic_ approach_control_cy_time\n",
      "Subsystem_No\n",
      "Stretched_ phase\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n",
      "E\n",
      "F\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the 2 CSV files as dataframe and list the name of the columns\n",
    "Signaldf = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.SM.csv')\n",
    "Signal_column = Signaldf.columns.tolist()\n",
    "# Print the column names\n",
    "for column in Signal_column:\n",
    " print(column)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n",
      "Site_ID\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n",
      "Detector_ID\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n",
      "Start_time\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n",
      "Traffic_Volume\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n",
      "Error\n",
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error\n",
      "0       8/03/2023     2366      2366-1    0:00:00               0  False\n",
      "1       8/03/2023     2366      2366-2    0:00:00               5  False\n",
      "2       8/03/2023     2366      2366-3    0:00:00               1  False\n",
      "3       8/03/2023     2366      2366-4    0:00:00               1  False\n",
      "4       8/03/2023     2366      2366-5    0:00:00               0  False\n",
      "...           ...      ...         ...        ...             ...    ...\n",
      "478651  8/03/2023     3112      3112-6   23:55:00               6  False\n",
      "478652  8/03/2023     3112     3112-17   23:55:00               1  False\n",
      "478653  8/03/2023     3112     3112-18   23:55:00               0  False\n",
      "478654  8/03/2023     3112     3112-19   23:55:00               2  False\n",
      "478655  8/03/2023     3112     3112-20   23:55:00               0  False\n",
      "\n",
      "[478656 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "TraffCount2df = pd.read_csv('C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/WEST_20230308.VS.csv')\n",
    "Traffic_column = TraffCount2df.columns.tolist()\n",
    "# Print the column names\n",
    "for column in Traffic_column:\n",
    " print(column)\n",
    " print(TraffCount2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date  Site_ID Detector_ID Start_time  Traffic_Volume  Error  \\\n",
      "0      2023-08-03     2366      2366-1   00:00:00               0  False   \n",
      "1      2023-08-03     2366      2366-2   00:00:00               5  False   \n",
      "2      2023-08-03     2366      2366-3   00:00:00               1  False   \n",
      "3      2023-08-03     2366      2366-4   00:00:00               1  False   \n",
      "4      2023-08-03     2366      2366-5   00:00:00               0  False   \n",
      "...           ...      ...         ...        ...             ...    ...   \n",
      "478651 2023-08-03     3112      3112-6   23:55:00               6  False   \n",
      "478652 2023-08-03     3112     3112-17   23:55:00               1  False   \n",
      "478653 2023-08-03     3112     3112-18   23:55:00               0  False   \n",
      "478654 2023-08-03     3112     3112-19   23:55:00               2  False   \n",
      "478655 2023-08-03     3112     3112-20   23:55:00               0  False   \n",
      "\n",
      "          Combined_datetime  \n",
      "0       2023-08-03 00:00:00  \n",
      "1       2023-08-03 00:00:00  \n",
      "2       2023-08-03 00:00:00  \n",
      "3       2023-08-03 00:00:00  \n",
      "4       2023-08-03 00:00:00  \n",
      "...                     ...  \n",
      "478651  2023-08-03 23:55:00  \n",
      "478652  2023-08-03 23:55:00  \n",
      "478653  2023-08-03 23:55:00  \n",
      "478654  2023-08-03 23:55:00  \n",
      "478655  2023-08-03 23:55:00  \n",
      "\n",
      "[478656 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "TraffCount2df['Date'] = pd.to_datetime(TraffCount2df['Date'])\n",
    "\n",
    "# Convert 'Start_time' column to datetime\n",
    "TraffCount2df['Start_time'] = pd.to_datetime(TraffCount2df['Start_time'], format='%H:%M:%S')\n",
    "\n",
    "# Modify the format of 'Start_time' column\n",
    "TraffCount2df['Start_time'] = TraffCount2df['Start_time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Create a new column combining 'Date' and 'Start_time'\n",
    "TraffCount2df['Combined_datetime'] = TraffCount2df['Date'].astype(str) + ' ' + TraffCount2df['Start_time']\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "print(TraffCount2df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nsdsc0\\OneDrive - WSP O365\\DATA_ANALYTICS\\Python\\SCATS\\Scats1.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Apply the custom function to fill the Detector Id columns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m detector_id \u001b[39min\u001b[39;00m filt_detec_ids:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     TraffCount2df[detector_id] \u001b[39m=\u001b[39m TraffCount2df\u001b[39m.\u001b[39;49mapply(fill_traffic_volume, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Print the updated TraffCount2df\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(TraffCount2df)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:8845\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8834\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8836\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   8837\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   8838\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8843\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   8844\u001b[0m )\n\u001b[1;32m-> 8845\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:733\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    731\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 733\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:857\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 857\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    859\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    871\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    872\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    874\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    875\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    876\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    877\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\nsdsc0\\OneDrive - WSP O365\\DATA_ANALYTICS\\Python\\SCATS\\Scats1.ipynb Cell 5\u001b[0m in \u001b[0;36mfill_traffic_volume\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Iterate over the filtered Detector Ids for Site ID 2368\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m detector_id \u001b[39min\u001b[39;00m filt_detec_ids:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m (row[\u001b[39m'\u001b[39;49m\u001b[39mDetector_ID\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m detector_id) \u001b[39mand\u001b[39;00m (row[\u001b[39m'\u001b[39m\u001b[39mSite_ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m site_id):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m traffic_volume\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nsdsc0/OneDrive%20-%20WSP%20O365/DATA_ANALYTICS/Python/SCATS/Scats1.ipynb#X60sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3619\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3614\u001b[0m \u001b[39mif\u001b[39;00m tolerance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3615\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   3616\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtolerance argument only valid if using pad, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3617\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbackfill or nearest lookups\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3618\u001b[0m     )\n\u001b[1;32m-> 3619\u001b[0m casted_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_cast_indexer(key)\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6290\u001b[0m, in \u001b[0;36mIndex._maybe_cast_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   6285\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6286\u001b[0m \u001b[39mIf we have a float key and are not a floating index, then try to cast\u001b[39;00m\n\u001b[0;32m   6287\u001b[0m \u001b[39mto an int if equivalent.\u001b[39;00m\n\u001b[0;32m   6288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_floating():\n\u001b[1;32m-> 6290\u001b[0m     \u001b[39mreturn\u001b[39;00m com\u001b[39m.\u001b[39;49mcast_scalar_indexer(key)\n\u001b[0;32m   6291\u001b[0m \u001b[39mreturn\u001b[39;00m key\n",
      "File \u001b[1;32mc:\\Users\\nsdsc0\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:160\u001b[0m, in \u001b[0;36mcast_scalar_indexer\u001b[1;34m(val, warn_float)\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mis_bool_list(key)\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcast_scalar_indexer\u001b[39m(val, warn_float: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    To avoid numpy DeprecationWarnings, cast float to integer where valid.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39m    outval : scalar\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39m# assumes lib.is_scalar(val)\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract the corresponding Detector_Ids\n",
    "filt_detec_ids = TraffCount2df.loc[TraffCount2df['Site_ID'] == 2368, 'Detector_ID']\n",
    "\n",
    "# Create new columns with extracted Detector_Ids\n",
    "for Detector_Id in filt_detec_ids:\n",
    "    TraffCount2df[Detector_Id] = None  # Initialize the new column with None\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "# print(TraffCount2df)\n",
    "\n",
    "# Define a custom function to fill the Detector Id columns\n",
    "def fill_traffic_volume(row):\n",
    "    site_id = row['Site_ID']\n",
    "    start_time = row['Start_time']\n",
    "    traffic_volume = row['Traffic_Volume']\n",
    "\n",
    "    # Iterate over the filtered Detector Ids for Site ID 2368\n",
    "    for detector_id in filt_detec_ids:\n",
    "        if (row['Detector_ID'] == detector_id) and (row['Site_ID'] == site_id):\n",
    "            return traffic_volume\n",
    "\n",
    "    return None  # Return None if no matching Detector Id is found\n",
    "\n",
    "# Apply the custom function to fill the Detector Id columns\n",
    "for detector_id in filt_detec_ids:\n",
    "    TraffCount2df[detector_id] = TraffCount2df.apply(fill_traffic_volume, axis=1)\n",
    "\n",
    "# Print the updated TraffCount2df\n",
    "print(TraffCount2df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
