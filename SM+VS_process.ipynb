{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "folder_path = 'Samples for WSP/SM/'\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "output_folder = 'output'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "combined_df['Date'].unique()\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each unique date in the \"Date\" column\n",
    "for date in combined_df['Date'].unique():\n",
    "    # Replace \"/\" with \"-\" in the date\n",
    "    formatted_date = date.replace(\"/\", \"-\")\n",
    "    \n",
    "    # Create a folder for the current date\n",
    "    date_folder = os.path.join(output_folder, formatted_date)\n",
    "    os.makedirs(date_folder, exist_ok=True)\n",
    "    single_date_df = combined_df[combined_df['Date'] == date]\n",
    "\n",
    "    # Convert 'Cycle_starttime' and 'Date' columns to datetime format\n",
    "    single_date_df['Cycle start time'] = pd.to_datetime(single_date_df['Cycle start time'])\n",
    "\n",
    "    single_date_df['Date'] = pd.to_datetime(single_date_df['Date'])\n",
    "\n",
    "    # Round the 'Cycle_starttime' column to the nearest 5-minute interval\n",
    "    single_date_df['Rounded_Time'] = single_date_df['Cycle start time'].dt.floor('5T')\n",
    "\n",
    "    # Combine 'Date' and 'Rounded_Time' into a new column\n",
    "    single_date_df['Combined_DateTime'] = single_date_df['Date'].astype(str) + ' ' + single_date_df['Rounded_Time'].dt.time.astype(str)\n",
    "\n",
    "    # Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "    single_date_df = single_date_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'})\n",
    "    # Move the 'Combined_DateTime' column to be the 5th column\n",
    "    cols = list(single_date_df.columns)\n",
    "    cols.insert(4, cols.pop(cols.index('Combined_DateTime')))\n",
    "    single_date_df = single_date_df[cols]\n",
    "    \n",
    "    for site_id in single_date_df['Site ID'].unique():\n",
    "        site_id_df = single_date_df[single_date_df['Site ID'] == site_id]\n",
    "        # Remove duplicate values in the 'Combined_DateTime' column\n",
    "        site_id_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "        # Drop Cycle_starttime column\n",
    "        site_id_df = site_id_df.drop('Cycle start time', axis=1)\n",
    "        single_date_df_folder = output_folder+\"/\"+formatted_date+f\"/{site_id}.csv\"\n",
    "        # Write the DataFrame to a CSV file\n",
    "        site_id_df.to_csv(single_date_df_folder, index=False)\n",
    "\n",
    "single_date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder path where your CSV files are located\n",
    "folder_path = 'Samples for WSP/VS/'\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dataframes1 = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df1 = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes1.append(df1)\n",
    "\n",
    "# Concatenate all the DataFrames into one\n",
    "combined_df1 = pd.concat(dataframes1, ignore_index=True)\n",
    "\n",
    "# # # Create the output folder if it doesn't exist\n",
    "# output_folder = 'output'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Print the combined DataFrame\n",
    "combined_df1['Date'].unique()\n",
    "combined_df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each unique date in the \"Date\" column\n",
    "for date in combined_df1['Date'].unique():\n",
    "    # Replace \"/\" with \"-\" in the date\n",
    "    formatted_date1 = date.replace(\"/\", \"-\")\n",
    "        # # Create a folder for the current date\n",
    "    # date_folder = os.path.join(output_folder, formatted_date)\n",
    "    # os.makedirs(date_folder, exist_ok=True)\n",
    "    TraffCountCHK7df = combined_df1[combined_df1['Date'] == date]\n",
    "    # Convert 'Start_time' column in Traffic Count data to datetime format\n",
    "    TraffCountCHK7df['Start time'] = pd.to_datetime(TraffCountCHK7df['Start time'])\n",
    "            # Create a new column 'Combined_DateTime' by combining 'Date' and 'Start_time'\n",
    "    TraffCountCHK7df['Combined_DateTime'] = TraffCountCHK7df['Date'].astype(str) + ' ' + TraffCountCHK7df['Start time'].dt.time.astype(str)\n",
    "    # Convert 'Combined_DateTime' column to datetime format\n",
    "    TraffCountCHK7df['Combined_DateTime'] = pd.to_datetime(TraffCountCHK7df['Combined_DateTime'])\n",
    "    # Round 'Combined_DateTime' column down to the nearest 5 minutes\n",
    "    TraffCountCHK7df['Rounded_Combined_DateTime'] = TraffCountCHK7df['Combined_DateTime'].dt.floor('5min')\n",
    "    #Filter the rows in the 'TraffCount3df' DataFrame where the 'Site_ID' column that has the value \"2368\"\n",
    "    for site_id in TraffCountCHK7df['Site ID'].unique():\n",
    "        site_idfilt7_df = TraffCountCHK7df[TraffCountCHK7df['Site ID'] == site_id]\n",
    "        # Pivot the DataFrame to create separate columns for each unique Detector_ID\n",
    "        site_idpivot7_df = site_idfilt7_df.pivot(index=['Combined_DateTime', 'Site ID'], columns='Detector ID', values='Traffic volume')\n",
    "        # Reset the index to make the combined DateTime and Site_ID columns regular columns\n",
    "        site_idpivot7_df = site_idpivot7_df.reset_index()\n",
    "        # Merge the pivoted DataFrame back into the original DataFrame based on the combined DateTime and Site_ID columns\n",
    "        site_idmerged7_df = site_idfilt7_df.merge(site_idpivot7_df, on=['Combined_DateTime', 'Site ID'], how='left')\n",
    "        # Remove the 'Combined_DateTime' column\n",
    "        site_idmerged7_df.drop('Combined_DateTime', axis=1, inplace=True)\n",
    "        # Rename the 'Rounded_Combined_DateTime' column to 'Combined_DateTime'\n",
    "        site_idmerged7_df.rename(columns={'Rounded_Combined_DateTime': 'Combined_DateTime'}, inplace=True)\n",
    "        # Drop the 'Detector_ID' column\n",
    "        site_idmerged7_df.drop('Detector ID', axis=1, inplace=True)\n",
    "        # Remove duplicate values in the 'Combined_DateTime' column\n",
    "        site_idmerged7_df.drop_duplicates(subset='Combined_DateTime', inplace=True)\n",
    "        # Drop Cycle_starttime column\n",
    "        site_idmerged7_df = site_idmerged7_df.drop(['Start time', 'Traffic volume'], axis=1)\n",
    "        # Convert 'Combined_DateTime' column to datetime format\n",
    "        site_idmerged7_df['Combined_DateTime'] = pd.to_datetime(site_idmerged7_df['Combined_DateTime'])\n",
    "        \n",
    "        #single_date_df_folder = output_folder+\"/\"+formatted_date+f\"/{site_idmerged7}.csv\"\n",
    "        # # Write the DataFrame to a CSV file\n",
    "        #site_idmerged7_df.to_csv(single_date_df_folder, index=False)            \n",
    "        # Print the updated DataFrame\n",
    "        site_idmerged7_df\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime column to string in both dataframes\n",
    "single_date_df['Combined_DateTime'] = single_date_df['Combined_DateTime'].astype(str)\n",
    "site_idmerged7_df['Combined_DateTime'] = site_idmerged7_df['Combined_DateTime'].astype(str)\n",
    "\n",
    "# Merge the single_date_df (Signal Phasing data) and the site_idmerged7_df (Traffic Volume data)\n",
    "\n",
    "Newmerged9_df = single_date_df.merge(site_idmerged7_df, on='Combined_DateTime')\n",
    "Newmerged9_df\n",
    "\n",
    "\n",
    "# # Rename the dataframe\n",
    "# new_df_name = f\"site{site_id}_date{date_value}\"\n",
    "# renamed_df = Newmerged9_df.copy()\n",
    "# renamed_df.name = new_df_name\n",
    "\n",
    "# # Specify the path and filename for the CSV file\n",
    "# Newmerged9 = f\"C:/Users/nsdsc0/OneDrive - WSP O365/DATA_ANALYTICS/Python/SCATS/Output/str(data_value)/{site_id}.csv\"\n",
    "\n",
    "# # Write the DataFrame to a CSV file\n",
    "# #Newmerged6_df.to_csv(Newmerged6, index=False)\n",
    "# #Newmerged6_df\n",
    "\n",
    "# # Save the renamed dataframe to a CSV file\n",
    "# csv_filename = f\"{new_df_name}.csv\"\n",
    "# renamed_df.to_csv(renamed, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
